{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms and Machine Learning\n",
    "\n",
    "## Target function\n",
    "\n",
    "One of the most imporant decision we have to make as data scientists is to define what constitutes success. \n",
    "\n",
    "This is an important concept that often gets overlooked. Results depend on our measure of success, and we should be informed about the choices that we made or the function that we are using has made for us.\n",
    "\n",
    "Today, we are going to discuss these concepts with an example with real data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we start by loading the Python packages that we are going to use in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #Package for numerical multidimensional tables\n",
    "import pandas as pd #Package for ...\n",
    "import matplotlib.pyplot as plt #Package for ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the years, I have had a discussion with colleagues about if Quentin Tarantino is a good director or merely over-hyped.\n",
    "\n",
    "To give the discussion some objective dimension, we decided to look at the ratings from Tarantino's movies through the years. The data comes from Rotten Tomatoes and it is saved in the 'RT_Tarantino.csv' file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load the data using a pandas data frame. And we print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset inclues ratings, title, year of release, and license cost for all Tarantino movies with a rating in Rotten Tomatoes. The data is presented in descending order through the years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to decide if Tarantino is a good director is to look at the rating of his latest movie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is certainly a valid measurement but it has some drawbacks. \n",
    "\n",
    "In particular, our whole decision depends on only the latest observation. \n",
    "\n",
    "Thus, it could change widly from year to year. For instance, we could get a completely different result if we had this discussion in 2008."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we look at the last rating available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of looking at the last rating we could look at the average rating for the last year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or some other year of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could consider the average for all his movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering all the data makes the measurement fairer in the sense that does not depent too much on anyone observation. \n",
    "\n",
    "Nonetheless, we may miss some important dynamics of his movies. Like, maybe Tarantino is directing better-rated movies now that when he started filming.\n",
    "\n",
    "As with most methods in statistical analysis, there are trade-offs to all decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the results through the years, there seems to be an increasing trend in the ratings. \n",
    "\n",
    "We can plot the data to *see* if our intention is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There does seems to be a slightly increasing trend on the ratings. Notice how the last movies have obtained hight ratings.\n",
    "\n",
    "We may be able to model this trend using a simple line.\n",
    "\n",
    "Thus, we try to *fit* the model\n",
    "$$Rating_i = \\alpha + \\beta Year_i + \\epsilon_i,$$\n",
    "where $\\alpha$ and $\\beta$ are selected according to some fit criteria. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "In the linear model above, the $\\epsilon_i$ allows us to capture random variations in the data that may not be explained using the linear fit.\n",
    "\n",
    "Thus, one intuitive way to select $\\alpha$ and $\\beta$ is to make them minimize the unexplained variations, $\\epsilon_i$. \n",
    "\n",
    "Let us call $\\widehat{Rating}_i$ to the rating assigned by the linear model. We may thus look to minimize\n",
    "$$\\min_{\\alpha,\\beta} \\epsilon_i = \\min_{\\alpha,\\beta} Rating_i-\\widehat{Rating}_i = \\min_{\\alpha,\\beta} Rating_i-\\alpha-\\beta Year_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two possible drawbacks with the above problem statement:\n",
    "* It is only based on one observation\n",
    "* It will get us undetermined solutions\n",
    "\n",
    "Why?\n",
    "\n",
    "* As was the case before with the simple mean, making our decision looking at just one observation may result in wildly different results depending on which observation we are looking at. So instead, we could take some certain combination of more values.\n",
    "* Notice that if we make $\\alpha$ smaller and smaller we get smaller values for $\\epsilon_i$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we must decide on a proper **loss function**.\n",
    "\n",
    "Our choice regarding the number and characteristics of the observations used, and the function used to weight them, produce different results.\n",
    "\n",
    "The classical linear regression proposes the loss function:\n",
    "$$\\mathcal{L}(\\alpha,\\beta) = \\sum_{i=1}^N (Rating_i-\\alpha-\\beta Year_i)^2,$$\n",
    "where $N$ is the number of observations used in the computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that nothing forces us to choose the square as the weighting function, we could have used absolute value or a higher degree polynomial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have selected our fit criteria (or loss function), we should decide how are we going to solve it. \n",
    "\n",
    "In this case, solving it translates to mininize the loss function.\n",
    "\n",
    "There are several options to look for a solution depending on the complexity of the problem at hand:\n",
    "* Try different combinations of $\\alpha$ and $\\beta$ and select the one with the smallest loss.\n",
    "* Start on a (possibly random) combination and use the data itself to point us to a better combination.\n",
    "* Solve the problem analytically. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "\n",
    "We start with the more intuitive way to look for a solution: grid search.\n",
    "\n",
    "The idea behind grid search is to set up a list or *grid* of values and then *search* for the optimal one. \n",
    "\n",
    "That is, we set a list of possible values for $\\alpha$ and $\\beta$, evaluate the loss function on them, and select the one that achieves the smallest values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the fitted model using the estimated parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try more values easily dy defining a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then make a list as big as we want to make the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we plot the line using the new estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another possible solution to our minimization algorithm is to start at a (possibly random) value and let the data itself tell us how to improve the fit. \n",
    "\n",
    "Mathematically, we know that the function decreases in the opposite direction of the derivative. This motivates to look for improvement in our loss function in the direction of the derivative.\n",
    "\n",
    "Thus, starting from some initial values, we update them as follows:\n",
    "\n",
    "$$\\alpha^{new} = \\alpha^{old}-\\frac{\\mathcal{L}(\\alpha,\\beta)}{\\partial{\\mathcal{L}(\\alpha,\\beta)}/\\partial{\\alpha}},$$\n",
    "$$\\beta^{new} = \\beta^{old}-\\frac{\\mathcal{L}(\\alpha,\\beta)}{\\partial{\\mathcal{L}(\\alpha,\\beta)}/\\partial{\\beta}},$$\n",
    "and we iterate until our parameters do not change (too much)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our purposes, we have already obtained the derivatives, they are given by:\n",
    "\n",
    "$$\\frac{\\partial{\\mathcal{L}(\\alpha,\\beta)}}{\\partial{\\alpha}} = -2\\sum_{i=1}^N(Rating_i-\\alpha-\\beta Year_i),$$\n",
    "$$\\frac{\\partial{\\mathcal{L}(\\alpha,\\beta)}}{\\partial{\\beta}} = -2\\sum_{i=1}^N(Rating_i-\\alpha-\\beta Year_i)Year_i,$$\n",
    "\n",
    "Which we define in Python below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the newly defined functions, we can update the values of our estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can plot the results with the last updated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More efficiently, we can set a *for* loop to update the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we plot the results with the last update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytical Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some problems, we may be able to obtain the analytical solution with pen and paper. \n",
    "\n",
    "Turns out, this is one of those examples. \n",
    "\n",
    "The solution is given by:\n",
    "\n",
    "$$\\hat{\\beta} = \\frac{ \\sum_{i=1}^N(Rating_i-\\overline{Rating})(Year_i-\\overline{Year})}{\\sum_{i=1}^N(Year_i-\\overline{Year})^2}$$\n",
    "\n",
    "$$\\hat{\\alpha} = \\overline{Rating}-\\hat{\\beta}\\overline{Year},$$\n",
    "where the bar on top means average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We program this into Python to obtain the analytical solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we plot the resulting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: What about the license cost to watch the movie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis\n",
    "\n",
    "The analysis above, gave us some values for the parameters in the linear model we considered. \n",
    "\n",
    "In particular, we found a positive value for the effect that $Year$ has on $Rating$; thus, it may seem that Tarantino's movies have been better received on average as times goes by. \n",
    "\n",
    "Yet, we may be interested in knowing if this result is a fluke (something due to chance given that we *randomly* decided to run the experiment *today*), or if there is perhaps some true better reception to his movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we would like to be able to say if the *positive* effect that $Year$ has on $Rating$ is **statistically significant**.\n",
    "\n",
    "There are two *cultures* regarding how to analyze if a result is significant:\n",
    "* Make a set of assumptions regarding the data and obtain analytical results\n",
    "* Use the data itself to check for the significance of the results\n",
    "\n",
    "As before, the methods above have advantages and disadvantages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normality Assumption\n",
    "\n",
    "If we are willing to assume that our data follows a specific probability distribution (typically a Normal distribution), then we know that the estimated parameter follows a Normal distribution. In particular\n",
    "\n",
    "$$\\hat{\\beta}\\sim \\mathcal{N}(\\beta,\\sigma^2_\\beta)$$\n",
    "\n",
    "Which tells us that our estimate is going to fall around the *true* value. \n",
    "\n",
    "Now, if the true value is non-zero, that would make it more likely that our estimate is non-zero. \n",
    "\n",
    "Moreover, the variance (how far our estimate can fall from the true value) decreases with the sample size. Thus, if our data is large enough, we can be quite certain of our results.\n",
    "\n",
    "Using the formula above, we can then compute the probability that it is non-zero by pure chance. \n",
    "\n",
    "If that probability is really small, we may be inclined to say that it is not just a random result but a true non-zero value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our purposes, the variance of $\\hat{\\beta}$ can be obtained by\n",
    "\n",
    "$$\\sigma^2_\\beta = \\frac{ \\mathcal{L}(\\hat{\\alpha},\\hat{\\beta})/(N-2)}{\\sum_{i=1}^N(Year_i-\\overline{Year})^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then plot a Normal distribution with mean 0 and variance given above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check graphically if the zero value is a likely result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously noted, this result relies on the Normality assumption. \n",
    "\n",
    "We should check if the data seems to follow a Normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does it look Normal? \n",
    "\n",
    "What about $Year$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, even if the data does not follow a Normal distribution, it can be shown that *asymptotically* it approximates it. \n",
    "\n",
    "So if the sample is big, the analysis above may still be valid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empirical Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For certain exercises, and when the data is far from being Normal, we can use the data itself to get some sense of the statistical validity of our results.\n",
    "\n",
    "Right now, we are producing just one general estimate of the parameters. As we did before, what if we could construct several estimates and study if they differ too much from each other.\n",
    "\n",
    "To generate more estimates we need new datasets. The data at hand is of course limited, we do not have an infinite number of Tarantino movies to obtain a bunch of parameter estimates. \n",
    "\n",
    "One way to generate more estimates from the fixed dataset is to randomly select a subset of the data, solve the model and obtain parameter estimates. If we do this enough times, we can construct an empirical distribution of the parameter.\n",
    "\n",
    "There are two main ways to generate *new* datasets from the data:\n",
    "* Drop some observations and estimate the model on the rest. We then repeat the experiment dropping another groups of observations. We typically drop just one observation, thus the name **leave-one-out**.\n",
    "* Randomly select a sample of the same size as the original by selection with replacement from the original dataset. The method is called **bootstrap**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leave-one-out\n",
    "\n",
    "We start with leave-one-out. We can sequenttially drop one observation, make the analysis in the rest of the data and store the parameter estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain the mean and variance of the estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain the mean and variance of the estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
